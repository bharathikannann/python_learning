{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____\n",
    "# Deep Neural Network\n",
    "_____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______\n",
    "## Activation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(Z):\n",
    "    \n",
    "    A = 1/(1+np.exp(-Z))\n",
    "    cache = Z\n",
    "    \n",
    "    return A, cache\n",
    "\n",
    "def relu(Z):\n",
    "    \n",
    "    A = np.maximum(0,Z)\n",
    "    \n",
    "    cache = Z \n",
    "    return A, cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradients for Activation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu_backward(dA, cache):\n",
    "    \n",
    "    Z = cache\n",
    "    dZ = np.array(dA, copy=True) # just converting dz to a correct object.\n",
    "    \n",
    "    # When z <= 0, you should set dz to 0 as well. \n",
    "    dZ[Z <= 0] = 0\n",
    "    \n",
    "    return dZ\n",
    "\n",
    "def sigmoid_backward(dA, cache):\n",
    "    \n",
    "    Z = cache\n",
    "    \n",
    "    s = 1/(1+np.exp(-Z))\n",
    "    dZ = dA * s * (1-s)\n",
    "    \n",
    "    return dZ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________________________\n",
    " ## Initializing Parameters\n",
    " \n",
    "- #### For 2 Layer Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(n_x, n_h, n_y):\n",
    "    \"\"\"\n",
    "    n_x -- size of the input layer\n",
    "    n_h -- size of the hidden layer\n",
    "    n_y -- size of the output layer\n",
    "    \"\"\"\n",
    "    \n",
    "    W1 = np.random.randn(n_h,n_x)*0.01\n",
    "    b1 = np.zeros((n_h,1))\n",
    "    W2 = np.random.randn(n_y,n_h)*0.01\n",
    "    b2 = np.zeros((n_y,1))\n",
    "    \n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"b1\": b1,\n",
    "                  \"W2\": W2,\n",
    "                  \"b2\": b2}\n",
    "    \n",
    "    return parameters    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- #### For N Layer Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters_deep(layer_dims):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    layer_dims -- python array (list) containing the dimensions of each layer in our network\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- python dictionary containing your parameters \"W1\", \"b1\", ..., \"WL\", \"bL\":\n",
    "                    Wl -- weight matrix of shape (layer_dims[l], layer_dims[l-1])\n",
    "                    bl -- bias vector of shape (layer_dims[l], 1)\n",
    "    \"\"\"\n",
    "    \n",
    "    np.random.seed(3)\n",
    "    parameters = {}\n",
    "    L = len(layer_dims)            # number of layers in the network\n",
    "\n",
    "    for l in range(1, L):\n",
    "        parameters['W' + str(l)] = np.random.randn(layer_dims[l],layer_dims[l-1])*0.01\n",
    "        parameters['b' + str(l)] = np.zeros((layer_dims[l],1))\n",
    "        \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______\n",
    "## Forward propagation module\n",
    "\n",
    "###  Linear Forward \n",
    "\n",
    "The linear forward module computes the following equations:\n",
    "\n",
    "$$Z^{[l]} = W^{[l]}A^{[l-1]} +b^{[l]}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_forward(A, W, b):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    A -- activations from previous layer (or input data): (size of previous layer, number of examples)\n",
    "    W -- weights matrix: numpy array of shape (size of current layer, size of previous layer)\n",
    "    b -- bias vector, numpy array of shape (size of the current layer, 1)\n",
    "\n",
    "    Returns:\n",
    "    Z -- the input of the activation function, also called pre-activation parameter \n",
    "    cache -- a python tuple containing \"A\", \"W\" and \"b\" ; stored for computing the backward pass efficiently\n",
    "    \"\"\"\n",
    "\n",
    "    Z = np.dot(W,A)+b\n",
    "    cache = (A, W, b)\n",
    "    \n",
    "    return Z, cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With Activation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_activation_forward(A_prev, W, b, activation):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    A_prev -- activations from previous layer (or input data): (size of previous layer, number of examples)\n",
    "    W -- weights matrix: numpy array of shape (size of current layer, size of previous layer)\n",
    "    b -- bias vector, numpy array of shape (size of the current layer, 1)\n",
    "    activation -- the activation to be used in this layer, stored as a text string: \"sigmoid\" or \"relu\"\n",
    "\n",
    "    Returns:\n",
    "    A -- the output of the activation function, also called the post-activation value \n",
    "    cache -- a python tuple containing \"linear_cache\" and \"activation_cache\";\n",
    "             stored for computing the backward pass efficiently\n",
    "    \"\"\"\n",
    "    \n",
    "    if activation == \"sigmoid\":\n",
    "        # Inputs: \"A_prev, W, b\". Outputs: \"A, activation_cache\".\n",
    "        Z, linear_cache = linear_forward(A_prev,W,b)\n",
    "        A, activation_cache = sigmoid(Z)\n",
    "    \n",
    "    elif activation == \"relu\":\n",
    "        # Inputs: \"A_prev, W, b\". Outputs: \"A, activation_cache\".\n",
    "        Z, linear_cache = linear_forward(A_prev,W,b)\n",
    "        A, activation_cache = relu(Z)\n",
    "\n",
    "    cache = (linear_cache, activation_cache)\n",
    "    \n",
    "    return A, cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For L Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_model_forward(X, parameters):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    X -- data, numpy array of shape (input size, number of examples)\n",
    "    parameters -- output of initialize_parameters_deep()\n",
    "    \n",
    "    Returns:\n",
    "    AL -- last post-activation value\n",
    "    caches -- list of caches containing:\n",
    "                every cache of linear_activation_forward() (there are L-1 of them, indexed from 0 to L-1)\n",
    "    \"\"\"\n",
    "\n",
    "    caches = []\n",
    "    A = X\n",
    "    L = len(parameters) // 2                  # number of layers in the neural network\n",
    "    \n",
    "    for l in range(1, L):\n",
    "        A_prev = A \n",
    "        A, cache = linear_activation_forward(A_prev,parameters[\"W\"+str(l)],parameters[\"b\"+str(l)],activation=\"relu\")\n",
    "        caches.append(cache)\n",
    "\n",
    "    AL, cache = linear_activation_forward(A,parameters[\"W\"+str(L)],parameters[\"b\"+str(L)],activation=\"sigmoid\")\n",
    "    caches.append(cache)\n",
    "            \n",
    "    return AL, caches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______\n",
    "## Cost function\n",
    "\n",
    "$$-\\frac{1}{m} \\sum\\limits_{i = 1}^{m} (y^{(i)}\\log\\left(a^{[L] (i)}\\right) + (1-y^{(i)})\\log\\left(1- a^{[L](i)}\\right))$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(AL, Y):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    AL -- probability vector corresponding to your label predictions, shape (1, number of examples)\n",
    "    Y -- true \"label\" vector (for example: containing 0 if non-cat, 1 if cat), shape (1, number of examples)\n",
    "\n",
    "    Returns:\n",
    "    cost -- cross-entropy cost\n",
    "    \"\"\"\n",
    "    \n",
    "    m = Y.shape[1]\n",
    "    cost = (-1/m)*np.sum(Y*np.log(AL)+(1-Y)*np.log(1-AL))\n",
    "    \n",
    "    cost = np.squeeze(cost)      # To make sure your cost's shape is what we expect (e.g. this turns [[17]] into 17).\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______\n",
    "## Backward Propogation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_backward(dZ, cache):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    dZ -- Gradient of the cost with respect to the linear output (of current layer l)\n",
    "    cache -- tuple of values (A_prev, W, b) coming from the forward propagation in the current layer\n",
    "\n",
    "    Returns:\n",
    "    dA_prev -- Gradient of the cost with respect to the activation (of the previous layer l-1), same shape as A_prev\n",
    "    dW -- Gradient of the cost with respect to W (current layer l), same shape as W\n",
    "    db -- Gradient of the cost with respect to b (current layer l), same shape as b\n",
    "    \"\"\"\n",
    "    A_prev, W, b = cache\n",
    "    m = A_prev.shape[1]\n",
    "\n",
    "    dW = (1/m)*np.dot(dZ,A_prev.T)\n",
    "    db = (1/m)*np.sum(dZ,axis=1,keepdims=True)\n",
    "    dA_prev = np.dot(W.T,dZ)\n",
    "    \n",
    "    return dA_prev, dW, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_activation_backward(dA, cache, activation):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    dA -- post-activation gradient for current layer l \n",
    "    cache -- tuple of values (linear_cache, activation_cache) we store for computing backward propagation efficiently\n",
    "    activation -- the activation to be used in this layer, stored as a text string: \"sigmoid\" or \"relu\"\n",
    "    \n",
    "    Returns:\n",
    "    dA_prev -- Gradient of the cost with respect to the activation (of the previous layer l-1), same shape as A_prev\n",
    "    dW -- Gradient of the cost with respect to W (current layer l), same shape as W\n",
    "    db -- Gradient of the cost with respect to b (current layer l), same shape as b\n",
    "    \"\"\"\n",
    "    linear_cache, activation_cache = cache\n",
    "    \n",
    "    if activation == \"relu\":\n",
    "        dZ = relu_backward(dA,activation_cache)\n",
    "        dA_prev, dW, db = linear_backward(dZ,linear_cache)\n",
    "        \n",
    "    elif activation == \"sigmoid\":\n",
    "        dZ = sigmoid_backward(dA,activation_cache)\n",
    "        dA_prev, dW, db = linear_backward(dZ,linear_cache)\n",
    "    \n",
    "    return dA_prev, dW, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_model_backward(AL, Y, caches):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    AL -- probability vector, output of the forward propagation (L_model_forward())\n",
    "    Y -- true \"label\" vector (containing 0 if non-cat, 1 if cat)\n",
    "    caches -- list of caches containing:\n",
    "                every cache of linear_activation_forward() with \"relu\" (it's caches[l], for l in range(L-1) i.e l = 0...L-2)\n",
    "                the cache of linear_activation_forward() with \"sigmoid\" (it's caches[L-1])\n",
    "    \n",
    "    Returns:\n",
    "    grads -- A dictionary with the gradients\n",
    "             grads[\"dA\" + str(l)] = ... \n",
    "             grads[\"dW\" + str(l)] = ...\n",
    "             grads[\"db\" + str(l)] = ... \n",
    "    \"\"\"\n",
    "    grads = {}\n",
    "    L = len(caches) # the number of layers\n",
    "    m = AL.shape[1]\n",
    "    Y = Y.reshape(AL.shape) # after this line, Y is the same shape as AL\n",
    "    \n",
    "    dAL = - (np.divide(Y, AL) - np.divide(1 - Y, 1 - AL))\n",
    "    \n",
    "    # Lth layer gradients. Inputs: \"dAL, current_cache\". Outputs: \"grads[\"dAL-1\"], grads[\"dWL\"], grads[\"dbL\"]\n",
    "    current_cache = caches[-1]\n",
    "    grads[\"dA\" + str(L-1)], grads[\"dW\" + str(L)], grads[\"db\" + str(L)] = linear_activation_backward(dAL,current_cache,\"sigmoid\")\n",
    "    \n",
    "    for l in reversed(range(L-1)):\n",
    "        # lth layer: gradients.\n",
    "        # Inputs: \"grads[\"dA\" + str(l + 1)], current_cache\". Outputs: \"grads[\"dA\" + str(l)] , grads[\"dW\" + str(l + 1)] , grads[\"db\" + str(l + 1)] \n",
    "        current_cache = caches[l]\n",
    "        dA_prev_temp, dW_temp, db_temp = linear_activation_backward(grads[\"dA\"+str(l+1)],current_cache,\"relu\")\n",
    "        grads[\"dA\" + str(l)] = dA_prev_temp\n",
    "        grads[\"dW\" + str(l + 1)] = dW_temp\n",
    "        grads[\"db\" + str(l + 1)] = db_temp\n",
    "\n",
    "    return grads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______\n",
    "## Update Parameters\n",
    "\n",
    "\n",
    "$$ W^{[l]} = W^{[l]} - \\alpha \\text{ } dW^{[l]} $$\n",
    "$$ b^{[l]} = b^{[l]} - \\alpha \\text{ } db^{[l]} $$\n",
    "\n",
    "- where $\\alpha$ is the learning rate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameters(parameters, grads, learning_rate):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    parameters -- python dictionary containing your parameters \n",
    "    grads -- python dictionary containing your gradients, output of L_model_backward\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- python dictionary containing your updated parameters \n",
    "                  parameters[\"W\" + str(l)] = ... \n",
    "                  parameters[\"b\" + str(l)] = ...\n",
    "    \"\"\"\n",
    "    \n",
    "    L = len(parameters) // 2 # number of layers in the neural network\n",
    "\n",
    "    for l in range(L):\n",
    "        parameters[\"W\" + str(l+1)] = parameters[\"W\"+str(l+1)]-learning_rate*grads[\"dW\"+str(l+1)]\n",
    "        parameters[\"b\" + str(l+1)] = parameters[\"b\"+str(l+1)]-learning_rate*grads[\"db\"+str(l+1)]\n",
    "        \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____\n",
    "## Predictions on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, y, parameters):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    X -- data set of examples you would like to label\n",
    "    parameters -- parameters of the trained model\n",
    "    \n",
    "    Returns:\n",
    "    p -- predictions for the given dataset X\n",
    "    \"\"\"\n",
    "    \n",
    "    m = X.shape[1]\n",
    "    n = len(parameters) // 2 # number of layers in the neural network\n",
    "    p = np.zeros((1,m))\n",
    "    \n",
    "    # Forward propagation\n",
    "    probas, caches = L_model_forward(X, parameters)\n",
    "\n",
    "    \n",
    "    # convert probas to 0/1 predictions\n",
    "    for i in range(0, probas.shape[1]):\n",
    "        if probas[0,i] > 0.5:\n",
    "            p[0,i] = 1\n",
    "        else:\n",
    "            p[0,i] = 0\n",
    "    \n",
    "    #print results\n",
    "    #print (\"predictions: \" + str(p))\n",
    "    #print (\"true labels: \" + str(y))\n",
    "    print(\"Accuracy: \"  + str(np.sum((p == y)/m)))\n",
    "        \n",
    "    return p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__________\n",
    "# Importing the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Titanic Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic = pd.read_csv('titanic_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x757c37beb8>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(titanic.isnull(),yticklabels=False,cbar=False,cmap='viridis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_age(cols):\n",
    "    Age = cols[0]\n",
    "    Pclass = cols[1]\n",
    "    \n",
    "    if pd.isnull(Age):\n",
    "\n",
    "        if Pclass == 1:\n",
    "            return 37\n",
    "\n",
    "        elif Pclass == 2:\n",
    "            return 29\n",
    "\n",
    "        else:\n",
    "            return 24\n",
    "\n",
    "    else:\n",
    "        return Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic['Age'] = titanic[['Age','Pclass']].apply(impute_age,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x757b37f7f0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(titanic.isnull(),yticklabels=False,cbar=False,cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.drop('Cabin',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Embarked  \n",
       "0      0         A/5 21171   7.2500        S  \n",
       "1      0          PC 17599  71.2833        C  \n",
       "2      0  STON/O2. 3101282   7.9250        S  \n",
       "3      0            113803  53.1000        S  \n",
       "4      0            373450   8.0500        S  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inserting Dummy Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sex = pd.get_dummies(titanic['Sex'],drop_first=True)\n",
    "embark = pd.get_dummies(titanic['Embarked'],drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.drop(['Sex','Embarked','Name','Ticket'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic = pd.concat([titanic,sex,embark],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>male</th>\n",
       "      <th>Q</th>\n",
       "      <th>S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass   Age  SibSp  Parch     Fare  male  Q  S\n",
       "0            1         0       3  22.0      1      0   7.2500     1  0  1\n",
       "1            2         1       1  38.0      1      0  71.2833     0  0  0\n",
       "2            3         1       3  26.0      0      0   7.9250     0  0  1\n",
       "3            4         1       1  35.0      1      0  53.1000     0  0  1\n",
       "4            5         0       3  35.0      0      0   8.0500     1  0  1"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_x=titanic.drop(['S'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_y=titanic.drop(['PassengerId','Survived','Pclass','Age','SibSp','Parch','Fare','male','Q'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(titanic_x, \n",
    "                                                    titanic_y, test_size=0.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_train.to_numpy().T\n",
    "X_test=X_test.to_numpy().T\n",
    "y_train=y_train.to_numpy().T\n",
    "y_test=y_test.to_numpy().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______\n",
    "# 2 - Layer Neural Network\n",
    "_______"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the number of units in all the layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "m=len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_x = m     \n",
    "n_h = 7\n",
    "n_y = 1\n",
    "layers_dims = (n_x, n_h, n_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_layer_model(X, Y, layers_dims, learning_rate = 0.0075, num_iterations = 3000, print_cost=False):\n",
    "    \"\"\"\n",
    "    Implements a two-layer neural network: LINEAR->RELU->LINEAR->SIGMOID.\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input data, of shape (n_x, number of examples)\n",
    "    Y -- true \"label\" vector (containing 1 if cat, 0 if non-cat), of shape (1, number of examples)\n",
    "    layers_dims -- dimensions of the layers (n_x, n_h, n_y)\n",
    "    num_iterations -- number of iterations of the optimization loop\n",
    "    learning_rate -- learning rate of the gradient descent update rule\n",
    "    print_cost -- If set to True, this will print the cost every 100 iterations \n",
    "    \n",
    "    Returns:\n",
    "    parameters -- a dictionary containing W1, W2, b1, and b2\n",
    "    \"\"\"\n",
    "    \n",
    "    np.random.seed(1)\n",
    "    grads = {}\n",
    "    costs = []                              # to keep track of the cost\n",
    "    m = X.shape[1]                           # number of examples\n",
    "    (n_x, n_h, n_y) = layers_dims\n",
    "    \n",
    "    parameters = initialize_parameters(n_x ,n_h ,n_y)\n",
    "    \n",
    "    W1 = parameters[\"W1\"]\n",
    "    b1 = parameters[\"b1\"]\n",
    "    W2 = parameters[\"W2\"]\n",
    "    b2 = parameters[\"b2\"]\n",
    "    \n",
    "\n",
    "    for i in range(0, num_iterations):\n",
    "\n",
    "        # Forward propagation: LINEAR -> RELU -> LINEAR -> SIGMOID. Inputs: \"X, W1, b1, W2, b2\". Output: \"A1, cache1, A2, cache2\".\n",
    "        A1, cache1 = linear_activation_forward(X,W1,b1,activation=\"relu\")\n",
    "        A2, cache2 = linear_activation_forward(A1,W2,b2,activation=\"sigmoid\")\n",
    "        # cache1=X,W1,b1,Z1\n",
    "        #cache2=A1,W2,b2,Z2\n",
    "        ### END CODE HERE ###\n",
    "        \n",
    "        cost = compute_cost(A2,Y)\n",
    "\n",
    "        dA2 = - (np.divide(Y, A2) - np.divide(1 - Y, 1 - A2))\n",
    "        \n",
    "        # Backward propagation. Inputs: \"dA2, cache2, cache1\". Outputs: \"dA1, dW2, db2; also dA0 (not used), dW1, db1\".\n",
    "        dA1, dW2, db2 = linear_activation_backward(dA2,cache2,activation=\"sigmoid\")\n",
    "        dA0, dW1, db1 = linear_activation_backward(dA1,cache1,activation=\"relu\")\n",
    "        \n",
    "        # Set grads['dWl'] to dW1, grads['db1'] to db1, grads['dW2'] to dW2, grads['db2'] to db2\n",
    "        grads['dW1'] = dW1\n",
    "        grads['db1'] = db1\n",
    "        grads['dW2'] = dW2\n",
    "        grads['db2'] = db2\n",
    "        \n",
    "        # Update parameters.\n",
    "        parameters = update_parameters(parameters,grads,learning_rate)\n",
    "\n",
    "        # Retrieve W1, b1, W2, b2 from parameters\n",
    "        W1 = parameters[\"W1\"]\n",
    "        b1 = parameters[\"b1\"]\n",
    "        W2 = parameters[\"W2\"]\n",
    "        b2 = parameters[\"b2\"]\n",
    "        \n",
    "        # Print the cost every 100 training example\n",
    "        if print_cost and i % 100 == 0:\n",
    "            print(\"Cost after iteration {}: {}\".format(i, np.squeeze(cost)))\n",
    "        if print_cost and i % 100 == 0:\n",
    "            costs.append(cost)\n",
    "       \n",
    "    # plot the cost\n",
    "\n",
    "    plt.plot(np.squeeze(costs))\n",
    "    plt.ylabel('cost')\n",
    "    plt.xlabel('iterations (per hundreds)')\n",
    "    plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "    plt.show()\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters = two_layer_model(X_train, y_train, layers_dims = (n_x, n_h, n_y), num_iterations = 2500, print_cost=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____\n",
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions_train = predict(X_train, y_train, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions_test = predict(X_test, y_test, parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________\n",
    "# L - Layer Deep Neural Network\n",
    "________\n",
    "- initializing the number of units in all the layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "m=len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers_dimsL = [m, 20, 7, 5, 1] #  4-layer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9, 20, 7, 5, 1]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers_dimsL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_layer_model(X, Y, layers_dimsL, learning_rate = 0.0075, num_iterations = 3000, print_cost=False):#lr was 0.009\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    X -- data, numpy array of shape (num_px * num_px * 3, number of examples)\n",
    "    Y -- true \"label\" vector (containing 0 if cat, 1 if non-cat), of shape (1, number of examples)\n",
    "    layers_dims -- list containing the input size and each layer size, of length (number of layers + 1).\n",
    "    learning_rate -- learning rate of the gradient descent update rule\n",
    "    num_iterations -- number of iterations of the optimization loop\n",
    "    print_cost -- if True, it prints the cost every 100 steps\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- parameters learnt by the model. They can then be used to predict.\n",
    "    cache1=X,W1,b1,Z1\n",
    "    cache2=A1,W2,b2,Z2\n",
    "    \"\"\"\n",
    "\n",
    "    np.random.seed(1)\n",
    "    costs = []                         # keep track of cost\n",
    "    \n",
    "    parameters = initialize_parameters_deep(layers_dimsL)\n",
    "\n",
    "    for i in range(0, num_iterations):\n",
    "\n",
    "        # Forward propagation: [LINEAR -> RELU]*(L-1) -> LINEAR -> SIGMOID.\n",
    "        AL, caches = L_model_forward(X,parameters)\n",
    "\n",
    "        \n",
    "        # Compute cost.\n",
    "        cost = compute_cost(AL,Y)\n",
    "\n",
    "        # Backward propagation.\n",
    "        grads = L_model_backward(AL,Y,caches)\n",
    " \n",
    "        # Update parameters.\n",
    "        parameters = update_parameters(parameters,grads,learning_rate)\n",
    "                \n",
    "        # Print the cost every 100 training example\n",
    "        if print_cost and i % 100 == 0:\n",
    "            print (\"Cost after iteration %i: %f\" %(i, cost))\n",
    "        if print_cost and i % 100 == 0:\n",
    "            costs.append(cost)\n",
    "            \n",
    "    # plot the cost\n",
    "    plt.plot(np.squeeze(costs))\n",
    "    plt.ylabel('cost')\n",
    "    plt.xlabel('iterations (per hundreds)')\n",
    "    plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "    plt.show()\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 0.643869\n",
      "Cost after iteration 100: 0.601657\n",
      "Cost after iteration 200: 0.597366\n",
      "Cost after iteration 300: 0.595718\n",
      "Cost after iteration 400: 0.593795\n",
      "Cost after iteration 500: 0.587718\n",
      "Cost after iteration 600: 0.587197\n",
      "Cost after iteration 700: 0.591025\n",
      "Cost after iteration 800: 0.583643\n",
      "Cost after iteration 900: 0.585924\n",
      "Cost after iteration 1000: 0.581569\n",
      "Cost after iteration 1100: 0.588036\n",
      "Cost after iteration 1200: 0.586024\n",
      "Cost after iteration 1300: 0.581382\n",
      "Cost after iteration 1400: 0.579127\n",
      "Cost after iteration 1500: 0.578648\n",
      "Cost after iteration 1600: 0.579359\n",
      "Cost after iteration 1700: 0.582284\n",
      "Cost after iteration 1800: 0.583233\n",
      "Cost after iteration 1900: 0.578975\n",
      "Cost after iteration 2000: 0.582459\n",
      "Cost after iteration 2100: 0.576732\n",
      "Cost after iteration 2200: 0.580352\n",
      "Cost after iteration 2300: 0.575682\n",
      "Cost after iteration 2400: 0.579356\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEWCAYAAAB1xKBvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAgAElEQVR4nO3deXxU9fX/8dc7O0tCWJKwbxJEFBTZRBS3anEprrVY9137s1ZttfqtrVZra6vdrLYVN1yriEup2rq0KooihFUJsgtEloQ1YUnIcn5/zI0OMQkTyGRC5jwfj3mQufdz75w7o/Oez733c6/MDOecc25PEmJdgHPOuf2DB4ZzzrmIeGA455yLiAeGc865iHhgOOeci4gHhnPOuYh4YLgWT9K/JV0c6zqc2995YLiokfSFpG/Fug4zO9nMnox1HQCS3pN0RRO8TqqkxyUVS1on6aY9tL8xaLc1WC41bF5vSe9K2iHp8/DPVNLfJW0Le5RJKgmb/56k0rD5i6Kzxa4peGC4/ZqkpFjXUK051QLcCeQCvYDjgFskja2toaRvA7cCJwC9gb7AL8Oa/AOYA3QEfgZMlpQFYGbXmFnb6kfQ9sUaL3FdWJsDG2n7XAx4YLiYkHSapLmStkj6SNLgsHm3SlomqURSvqQzw+ZdImmapD9K2gTcGUz7UNL9kjZLWiHp5LBlvvpVH0HbPpKmBq/9jqSHJD1TxzYcK6lA0k8lrQOekNRe0muSioL1vyape9D+HuBo4MHg1/aDwfQBkt6WtEnSIknnNsJbfBFwt5ltNrOFwCPAJXW0vRh4zMwWmNlm4O7qtpL6A4cDd5jZTjN7CfgUOLuW96NNML1Z9OZc4/PAcE1O0uHA48DVhH61PgxMCdsNsozQF2s7Qr90n5HUJWwVI4HlQDZwT9i0RUAn4HfAY5JURwn1tX0OmBHUdSdw4R42pzPQgdAv+asI/T/1RPC8J7ATeBDAzH4GfMDXv7ivC75k3w5eNxs4D/irpINrezFJfw1CtrbH/KBNe6ArMC9s0XlAresMptdsmyOpYzBvuZmV1Jhf27rOBoqAqTWm/0bShiDoj62jBrcf8MBwsXAl8LCZfWJmlcHxhTLgCAAze9HM1phZlZm9ACwBRoQtv8bM/mJmFWa2M5i20sweMbNKQr9wuwA5dbx+rW0l9QSGA78ws11m9iEwZQ/bUkXo13dZ8At8o5m9ZGY7gi/Ze4Bj6ln+NOALM3si2J7ZwEvAObU1NrMfmFlmHY/qXlrb4N+tYYtuBdLrqKFtLW0J2tecV9+6Lgaest0vUPdTQru4ugETgH9JOqCOOlwz54HhYqEX8OPwX8dAD0K/ipF0Udjuqi3AIYR6A9VW17LOddV/mNmO4M+2tbSrr21XYFPYtLpeK1yRmZVWP5HUWtLDklZKKib0aztTUmIdy/cCRtZ4L84n1HPZW9uCfzPCpmUAJbW0rW5fsy1B+5rzal2XpB6EgvGp8OnBj4KSIFCfBKYBp0S4Ha6Z8cBwsbAauKfGr+PWZvYPSb0I7W+/DuhoZpnAZ0D47qVoXWJ5LdBBUuuwaT32sEzNWn4MHAiMNLMMYEwwXXW0Xw28X+O9aGtm19b2YrWclRT+WAAQHIdYCxwatuihwII6tmFBLW3Xm9nGYF5fSek15tdc10XAR2a2vI7XqGbs/lm6/YgHhou2ZElpYY8kQoFwjaSRCmkj6dTgS6kNoS+VIgBJlxLqYUSdma0E8ggdSE+RNAr4TgNXk07ouMUWSR2AO2rMX09oF02114D+ki6UlBw8hks6qI4adzsrqcYj/LjCU8DtwUH4AYR2A06so+angMslDQyOf9xe3dbMFgNzgTuCz+9MYDCh3WbhLqq5fkmZkr5d/blLOp9QgL5ZRx2umfPAcNH2BqEv0OrHnWaWR+gL7EFgM7CU4KwcM8sHfg98TOjLdRCh3RhN5XxgFLAR+BXwAqHjK5H6E9AK2ABMB/5TY/6fgXOCM6geCI5znASMB9YQ2l32WyCVfXMHoZMHVgLvA/eZ2X8AJPUMeiQ9AYLpvwPeDdqvZPegGw8MI/RZ3QucY2ZF1TODYO3ON0+nTSb0HhYRej9+CJxhZj4WYz8lv4GSc3WT9ALwuZnV7Ck4F3e8h+FcmGB30AGSEhQa6HY68Gqs63KuOWhOI1Odaw46Ay8TGodRAFxrZnNiW5JzzYPvknLOORcR3yXlnHMuIi1ml1SnTp2sd+/esS7DOef2K7NmzdpgZlmRtG0xgdG7d2/y8vJiXYZzzu1XJK2MtK3vknLOORcRDwznnHMR8cBwzjkXEQ8M55xzEfHAcM45FxEPDOeccxHxwHDOOReRuA+MrTvL+dM7i5m3ekusS3HOuWYt7gMD4E/vLGHmF5tiXYZzzjVrcR8YGWlJpCUnsG5r6Z4bO+dcHIv7wJBE54w01pc05KZqzjkXf+I+MACyM9JY7z0M55yrlwcGBD0MDwznnKuPBwaQk5HKuq2l+M2knHOubh4YQE5GGmUVVWzdWR7rUpxzrtnywAA6t0sDYH2xH/h2zrm6RDUwJI2VtEjSUkm31tHmXEn5khZIeq7GvAxJX0p6MJp15mSEAmNdsR/HcM65ukTtjnuSEoGHgBOBAmCmpClmlh/WJhe4DRhtZpslZddYzd3A+9GqsVrnjOoehgeGc87VJZo9jBHAUjNbbma7gOeB02u0uRJ4yMw2A5hZYfUMSUOBHOCtKNYIQFZ6KoCfWuucc/WIZmB0A1aHPS8IpoXrD/SXNE3SdEljASQlAL8Hbq7vBSRdJSlPUl5RUdFeF5qWnEj71sl+aq1zztUjmoGhWqbVPG81CcgFjgXOAx6VlAn8AHjDzFZTDzObYGbDzGxYVlbWPhWbk5HGuq1+0Ns55+oStWMYhHoUPcKedwfW1NJmupmVAyskLSIUIKOAoyX9AGgLpEjaZma1HjhvDDkZaRR6D8M55+oUzR7GTCBXUh9JKcB4YEqNNq8CxwFI6kRoF9VyMzvfzHqaWW/gJ8BT0QwL+HrwnnPOudpFLTDMrAK4DngTWAhMMrMFku6SNC5o9iawUVI+8C5ws5ltjFZN9emckcaGbWVUVFbF4uWdc67Zi+YuKczsDeCNGtN+Efa3ATcFj7rWMRGYGJ0Kv5adkUaVwYZtu74ayOecc+5rPtI74GMxnHOufh4YAR/t7Zxz9fPACOS0Cw3eK/TAcM65WnlgBDq1SSUxQd7DcM65OnhgBBISRHZ6ql+x1jnn6uCBESYnI80PejvnXB08MML44D3nnKubB0aYzt7DcM65OnlghMnOSKO4tIKduypjXYpzzjU7HhhhfPCec87VzQMjjA/ec865unlghOkcDN7zHoZzzn2TB0aYbN8l5ZxzdfLACJOemkTrlEQfvOecc7XwwAgjKXSrVu9hOOfcN3hg1JCTkeoXIHTOuVp4YNTgPQznnKudB0YNodHeZYRuBuicc66aB0YNORlp7KqoYsuO8liX4pxzzYoHRg3Vg/fWl/huKeecCxfVwJA0VtIiSUsl3VpHm3Ml5UtaIOm5YFovSbMkzQ2mXxPNOsNVD97zq9Y659zukqK1YkmJwEPAiUABMFPSFDPLD2uTC9wGjDazzZKyg1lrgSPNrExSW+CzYNk10aq3WnZ6qIdR6GMxnHNuN9HsYYwAlprZcjPbBTwPnF6jzZXAQ2a2GcDMCoN/d5lZ9Td2apTr3E12RtDD8DOlnHNuN9H8Iu4GrA57XhBMC9cf6C9pmqTpksZWz5DUQ9L8YB2/ra13IekqSXmS8oqKihql6NSkRDq0SfHAcM65GqIZGKplWs1zVZOAXOBY4DzgUUmZAGa22swGA/2AiyXlfGNlZhPMbJiZDcvKymq0wnMy0nzwnnPO1RDNwCgAeoQ97w7U7CUUAP80s3IzWwEsIhQgXwl6FguAo6NY625yMlK9h+GcczVEMzBmArmS+khKAcYDU2q0eRU4DkBSJ0K7qJZL6i6pVTC9PTCaUJg0ierBe845574WtcAwswrgOuBNYCEwycwWSLpL0rig2ZvARkn5wLvAzWa2ETgI+ETSPOB94H4z+zRatdaUnZHGhm1llFdWNdVLOudcsxe102oBzOwN4I0a034R9rcBNwWP8DZvA4OjWVt9OmekYQYbtpXRpV2rWJXhnHPNio/0rkVOhg/ec865mjwwavHV5UH8OIZzzn3FA6MWndv5rVqdc64mD4xadGidQnKiPDCccy6MB0YtEhJEdrrfSMk558J5YNQhOyPVL0DonHNhPDDq0Nlv1eqcc7vxwKhDTkaaH8NwzrkwHhh1yMlIo6S0gh27KmJdinPONQseGHWoHrznYzGccy7EA6MOnYPBez7a2znnQjww6pCd4YP3nHMunAdGHXy0t3PO7c4Dow5tU5Nok5Lop9Y651zAA6MeOe3SfPCec84FPDDqkeOXB3HOua94YNSjczsfvOecc9U8MOqRkxHaJRW6MaBzzsU3D4x65GSksquyis07ymNdinPOxZwHRj188J5zzn0tqoEhaaykRZKWSrq1jjbnSsqXtEDSc8G0wyR9HEybL+l70ayzLl8N3ivxwHDOuaRorVhSIvAQcCJQAMyUNMXM8sPa5AK3AaPNbLOk7GDWDuAiM1siqSswS9KbZrYlWvXW5qvBe97DcM65qPYwRgBLzWy5me0CngdOr9HmSuAhM9sMYGaFwb+LzWxJ8PcaoBDIimKttcpq6xcgdM65atEMjG7A6rDnBcG0cP2B/pKmSZouaWzNlUgaAaQAy2qZd5WkPEl5RUVFjVh6SEpSAp3apvhYDOecI7qBoVqm1Tw/NQnIBY4FzgMelZT51QqkLsDTwKVmVvWNlZlNMLNhZjYsKys6HZDs9DQKPTCccy6qgVEA9Ah73h1YU0ubf5pZuZmtABYRChAkZQCvA7eb2fQo1lmvzu18tLdzzkF0A2MmkCupj6QUYDwwpUabV4HjACR1IrSLannQ/hXgKTN7MYo17lFORqofw3DOOaIYGGZWAVwHvAksBCaZ2QJJd0kaFzR7E9goKR94F7jZzDYC5wJjgEskzQ0eh0Wr1vrkZKSxcXsZ5ZXf2CPmnHNxJWqn1QKY2RvAGzWm/SLsbwNuCh7hbZ4BnolmbZHKyUjDDIpKyuia2SrW5TjnXMz4SO89+Gq0tx/HcM7FOQ+MPcjJ8MF7zjkHHhh7lJNRPXjPA8M5F988MPagQ5sUkhPFOj9TyjkX5zww9kCSD95zzjk8MCLig/ecc84DIyKhwXseGM65+OaBEYGcjDQf7e2ci3seGBHIyUhjW1kF28oqYl2Kc87FjAdGBKoH7/luKedcPPPAiEC2j8VwzjkPjEh4D8M55zwwIvLV5UH8wLdzLo55YESgTWoS6alJrPPrSTnn4pgHRoSyM1IpLPHAcM7FLw+MCHVul+Y9DOdcXIsoMCR9N5JpLZkP3nPOxbtIexi3RTitxcrJSKOwpJSqKot1Kc45FxP13qJV0snAKUA3SQ+EzcoA4mrYc+eMNMorjU07dtGpbWqsy3HOuSa3p3t6rwHygHHArLDpJcCN0SqqOQq/kZIHhnMuHtW7S8rM5pnZk0A/M3sy+HsKsNTMNu9p5ZLGSlokaamkW+toc66kfEkLJD0XNv0/krZIeq2B2xQVOT54zzkX5/bUw6j2tqRxQfu5QJGk983sproWkJQIPAScCBQAMyVNMbP8sDa5hI6FjDazzZKyw1ZxH9AauLpBWxQlPnjPORfvIj3o3c7MioGzgCfMbCjwrT0sM4JQT2S5me0CngdOr9HmSuCh6t6KmRVWzzCz/xLa9dUsZKWnIuGn1jrn4lakgZEkqQtwLhDpLqJuwOqw5wXBtHD9gf6SpkmaLmlshOsGQNJVkvIk5RUVFTVk0QZLTkygYxsfvOeci1+RBsZdwJvAMjObKakvsGQPy6iWaTXPSU0CcoFjgfOARyVlRlgTZjbBzIaZ2bCsrKxIF9trnduleg/DORe3IjqGYWYvAi+GPV8OnL2HxQqAHmHPuxM666pmm+lmVg6skLSIUIDMjKSuppaTnsZaDwznXJyKdKR3d0mvSCqUtF7SS5K672GxmUCupD6SUoDxhM6wCvcqcFzwGp0I7aJa3rBNaDo57dL8LCnnXNyKdJfUE4S+7LsSOg7xr2BancysAriO0K6shcAkM1sg6a7gjCuCeRsl5QPvAjeb2UYASR8Q6tWcIKlA0rcbtmmNLyc9jY3bd7GroirWpTjnXJOL9LTaLDMLD4iJkm7Y00Jm9gbwRo1pvwj724CbgkfNZY+OsLYm07ldaMBeYUkp3du3jnE1zjnXtCLtYWyQdIGkxOBxAbAxmoU1Rz4WwzkXzyINjMsInVK7DlgLnANcGq2imisf7e2ci2eR7pK6G7i4eoCdpA7A/YSCJG74vb2dc/Es0h7G4PBrR5nZJmBIdEpqvjJbJ5OSlMA6DwznXByKNDASJLWvfhL0MCLtnbQYksjJSKXQj2E45+JQpF/6vwc+kjSZ0Gjtc4F7olZVM5aT7rdqdc7Fp0hHej8lKQ84ntAlP84Kv+psPMlpl8bCNcWxLsM555pcxLuVgoCIy5AIl5OexnvFhXtu6JxzLUykxzBcoHO7VLbvqqSktDzWpTjnXJPywGggH7znnItXHhgN5IP3nHPxygOjgTwwnHPxygOjgXIyQhcg9MF7zrl444HRQK1TkkhPS/LBe865uOOBsRc6Z/jgPedc/PHA2Aud26WxvsQDwzkXXzww9kJ2ehrrvYfhnIszHhh7oXO7VApLyqiqsliX4pxzTcYDYy90y2xNRZXxxmdrY12Kc841GQ+MvTDusK4M7dWeHz0/l3/NWxPrcpxzrklENTAkjZW0SNJSSbfW0eZcSfmSFkh6Lmz6xZKWBI+Lo1lnQ7VNTeLJy0YwtGd7fvT8HF6d82WsS3LOuaiLWmBISgQeAk4GBgLnSRpYo00ucBsw2swOBm4IpncA7gBGAiOAO8Jv4NQctE1NYuJlwxnZpyM3TprL5FkFsS7JOeeiKpo9jBHAUjNbbma7gOeB02u0uRJ4qPr2r2ZWfd3wbwNvm9mmYN7bwNgo1rpXWqck8fglwzmqXydunjyPF2auinVJzjkXNdEMjG7A6rDnBcG0cP2B/pKmSZouaWwDlkXSVZLyJOUVFRU1YumRa5WSyCMXDWNMbhY/felTnpm+MiZ1OOdctEUzMFTLtJrnoSYBucCxwHnAo5IyI1wWM5tgZsPMbFhWVtY+lrv30pITmXDRUE4YkM3tr37Gkx99EbNanHMuWqIZGAVAj7Dn3YGapxQVAP80s3IzWwEsIhQgkSzbrKQmJfK3C4Zy0sAc7piygEc/WB7rkpxzrlFFMzBmArmS+khKAcYDU2q0eRU4DkBSJ0K7qJYDbwInSWofHOw+KZjWrKUkJfDQ+YdzyqDO/Or1hfz9/WWxLsk55xpNxPf0bigzq5B0HaEv+kTgcTNbIOkuIM/MpvB1MOQDlcDNZrYRQNLdhEIH4C4z2xStWhtTcmICD4wfQmLCPO799+dUVFZx3fG5sS7LOef2mcxaxuUthg0bZnl5ebEu4ysVlVXcPHk+r8z5khu+lcuPTshFqu3QjHPOxY6kWWY2LJK2UethxLukxATu/+6hJCaIP72zhIpK48cn9ffQcM7ttzwwoigxQfzu7MEkJ4oH313Kmq07uWx0Hw7umuHB4Zzb73hgRFlCgrjnjEFktErmiWlf8PLsLxnQOZ1zhnbnjCHd6NQ2NdYlOudcRPwYRhPauqOcKfPXMHlWAfNWbyEpQRw3IJtzhnbn+AHZJCf6tSCdc02rIccwPDBiZPH6El6aVcDLc76kqKSMjm1SOP2wbpwztDsDu2bEujznXJzwwNiPVFRWMXVJES/mFfDOwvWUVxoHd83gnKHdOf2wbnRokxLrEp1zLZgHxn5q8/ZdTJm3hhdnreazL4tJThSnDOrC5Uf1YXD3zFiX55xrgTwwWoCFa4t5YeZqJs8qYFtZBcN6tefyo/pw4sAckvxYh3OukXhgtCAlpeVMyitg4kcrWL1pJ90yW3Hp6N6cO7wHGWnJsS7PObef88BogSqrjLfz1/P4tBXMWLGJNimJfHdYDy4d3ZteHdvEujzn3H7KA6OF+7RgK49PW8Fr89dQUWV866AcLhvdhyP6dvABgc65BvHAiBPri0t5+uOVPPvJSjbvKGdglwyuGtOX0w/r6sHhnItIQwLDj57ux3Iy0vjJtw/k49tO4DdnDaK8soobXpjLpLzVe17YOecayAOjBUhLTuS8ET1584YxHHlAR+6cks+yom2xLss518J4YLQgCQniD+ceRlpyAtf/Yw5lFZWxLsk514J4YLQwndul8duzB7NgTTG/f2txrMtxzrUgHhgt0EkHd+aCI3oyYepypi4uinU5zrkWwgOjhbr91IHkZrflpknz2LCtLNblOOdaAA+MFiotOZEHzhtCcWk5t0yeT0s5fdo5FzseGC3YQV0y+L+TB/C/zwt56uOVMaujvLKKz77c6qHl3H4uqoEhaaykRZKWSrq1lvmXSCqSNDd4XBE277eSPgse34tmnS3ZxUf25vgB2dzzxkI+X1fc5K9fUlrOZRNnctpfPmTKvDVN/vrOucYTtcCQlAg8BJwMDATOkzSwlqYvmNlhwePRYNlTgcOBw4CRwM2S/K5Ce0ES950zmHatkrn+H3MoLW+6U23XbS3l3Ien89GyjXTLbMWv31jItrKKJnt951zjimYPYwSw1MyWm9ku4Hng9AiXHQi8b2YVZrYdmAeMjVKdLV7Htqn8/ruHsnj9Nu55fWGTvObn64o586/TWLVxO49fMpy/fH8I64vL+Mv/ljTJ6zvnGl80A6MbEH6NioJgWk1nS5ovabKkHsG0ecDJklpL6gQcB/SouaCkqyTlScorKvLTR+szpn8WVx7dh6enr+Tt/PVRfa1pSzfw3b99TJUZk64ZxTH9szi8Z3vOGdqdxz9c4aPQndtPRTMwarv6Xc2jnv8CepvZYOAd4EkAM3sLeAP4CPgH8DHwjX0ZZjbBzIaZ2bCsrKzGrL1FuvnbAzikWwa3TJ7H+uLSqLzGS7MKuPjxGXTNbMUrPxjNwV3bfTXvp2MHkJaUyJ1TFvgBcOf2Q9EMjAJ27xV0B3Y76mlmG82sepDAI8DQsHn3BMc1TiQUPr4vYx+lJCXw5/FDKC2v4qZJc6mqarwvbTPjz+8s4ccvzmNk3w68eO0ouma22q1NVnoqN57Ynw+WbOCtKPdynHONL5qBMRPIldRHUgowHpgS3kBSl7Cn44CFwfRESR2DvwcDg4G3olhr3Dggqy13jhvItKUbmfDB8kZZZ3llFT99aT5/fGcxZx3ejScuGVHn3QAvHNWL/jltufu1/CY9AO+c23dRCwwzqwCuA94kFASTzGyBpLskjQuaXS9pgaR5wPXAJcH0ZOADSfnABOCCYH2uEZw7rAenDurC/W8uYn7Bln1aV/Vps5PyCrj+hFx+/91DSUmq+z+r5MQE7hx3MAWbd/L395ft02s755qW30ApTm3dUc7Jf55KSlICr19/NG1Skxq8jnVbS7l04kwWry/hN2cO4tzh3zgvoU7XPTebt/PX885Nx9CjQ+sGv3asfLRsA1MXb+D8kT33q7qdq4vfcc9FZMaKTYyf8DGDumdyeM9MumW2oltmK7pmtqJb+1Z0bJNS5537Pl9XzKVPzKR4Zzl/vWAox/Rv2EkHa7fu5Pj73+fo3E5MuCii/1ZjrqikjJP++D6bd5STIDhlUBeuHnMAg7q32/PCzjVTDQmMhv+sdC3GiD4duOv0Q3jq4y+YNHM123ftfkwhNSnh6wAJ/u2amYYkfjllAa1TE5l0zajdzoSKVJd2rbju+H7c9+Yi3l9c1ODAaWpmxv+98inbd1Xy7BUjmbqkiOemr+K1+WsZ3a8jV485gKNzO/mtcV2L5j0MB4S+EIt3VlCwZQdrtpTy5eYdrNlaypdbdvLl5p2s2bKTwpKvr3p7YE46T1w6/BtnQjVEWUUl3/7jVBIk/nPDmHqPfcTay7MLuGnSPH52ykFcOaYvAMWl5fzjk1U89uEKCkvKOKhLBtcc05dTBnUhObH5botz4XyXlIuKsopK1m0tpbCkjIO7ZtA6Zd87qO8uKuTSJ2Zy68kDuOaYAxqhysa3dutOTvrjVA7MSeeFq0eRmLB7L6KsopJ/zl3DhKnLWVq4jW6Zrbj8qD58b3iPvTo25FxT8sBw+5UrnpzJx8s28t8fH0vndmmxLmc3ZsbFT8xk5opN/PtHR9O7U5s621ZVGf/7vJCHpy5j5hebadcqmYtG9eLiI3vTqW1qE1btXOQaEhjeb3Yx9/PTBlJeZfzm33t/nauduyp5evpKFq5t3CvyPj9zNVMXF3HryQPqDQsI3VP9WwNzePGaI3np2lGM7NOBB99dypH3/o9HG2nMi3Ox5P1lF3O9OrbhmjF9eeB/S/n+iJ6M7Nsx4mXLKip5fsZqHnx3KUUlZaSnJfHM5SM5tEfmPte1etMOfvVaPqP6duTCI3o1aNmhvTow4aIOLCvaxm/eWMivXl9IalICF47qvc91ORcr3sNwzcK1x/ajW2Yr7piygIrKqj22r6isYlLeao6//33umLKAPp3a8PcLhpLZOpkLHvuEuav3bUBiVZVxy+T5APzunMEkJOzd2U8HZLXlbxcM5VsHZfPzfy7glTkF+1SXc7HkgeGahVYpidx+6kF8vq6EZz9ZVWe7qirjtflrOOlPU7ll8nw6tk3hqctG8MJVRzD2kM48f9Uo2rdO4cJH9y00np6+ko+Xb+T20wbu8wC95MQEHvz+4Rx5QEd+8uJ83lywbp/W51yseGC4ZmPsIZ05ql8nfv/WIjZsK9ttnpnxv8/Xc+pfPuS65+aQlCD+fsFQ/vn/RjOmf9ZX4x+6Zbbi+auOoEPbUGjMWbW5wXWs2LCde//9Ocf0z2J8A0av1yctOZFHLhrGoG7t+OFzc/hgiV+O3+1/PDBcsyGJO8cNZMeuSu77z6Kvpn+8bCNn/+0jLpuYx/ayCv74vUP594/GMPaQzrUOlOsaHhqPzWB2A0Kjssr4yYvzSE4Uvz17cKMOxGuTmsTES8apDHcAABRoSURBVIfTN6sNVz01i1krNzXaup1rCh4Yrlnpl53OZUf1YdKs1Tw/YxUXPPoJ5z0ynTVbSvn1mYP474+P4cwh3b8xFqKmLu1CodGpbQoXPTaDWSsjC43HPlzOrJWbuXPcwVE5xTezdQpPXT6Czu3SuOSJmSxYs7XRX8O5aPHAcM3OD4/vR6e2qdz68qfkry3m9lMP4r2bj+X7I3s2aAR1KDRG0altChc/PmOPv+iXrC/h/rcWc+LAHM4cUtvNIRtHdnoaz1wxkvTUJC56bAZLC/0OhG7/4AP3XLM084tNzFu9hfEjetJ2H0dLr9taynmPTKewuJSnLh/B0F4dvtGmorKKs//2Eas27eCtG48hKz36A+2WF23j3Ic/JjkxgRevGUX39vF79duyikry1xQzZ9UWPv1yK0N7teeCBp7K7PaOj/R2robw0HjyshEM6717aDz4vyXc/9ZiHvz+EE4b3LXJ6spfU8z4CR/ToU0Kk64ZRXZ68xrpHg1mRsHmncxetZk5q7Ywd/UW8tcUsys4nTojLYni0gquPyGXG7+V6xd0jDIPDOdqsb64lPMmTGd9cSkTLxvB8CA08tcUc/pDH3LSwZ156PuHN3lds1dt5oJHP6FH+9a8cPURZLZOafIaoqm4tJz5q7cyd/XXAbFx+y4A0pITGNw9kyE9MhnSM5PDerQnKz2V216ez6S8Aq455gB+OvbARg+Ngs07mL1qC98Z3CXuA8kDw7k6FBaXMv6R6azbWsrES0dwWI9Mxj34IRu27eKtG8fQoU1svqynLd3ApU/M5KCuGTx7xch93g3XHGzdWc6vXstn8uwCqr9mDshqw2E92gfhkMmAzukk1XJcqqrK+MWUz3hm+iouG92Hn592UKN9sX+wpIgf/mMOW3aU88txB3Pxkb0bZb37Kw8M5+pRWBzaPbV2aynHHZjN65+u5ZGLhnHiwJyY1vXWgnVc++xshvduz8RLR5CWnBjTevbFu4sKue2lTynaVsaFR/Ti+AHZHNo9k3ata7/Xe23MjLtey+eJaV9w4RG9+OW4g/d6xH31+h6eupzf/edzcrPTyUpP5ZMVG5l09SiG9Gy/1+vd33lgOLcHhSWh3VPLirZz1uHd+MO5h8W6JABenfMlN06ay3EHZvPg94c0yiXkm1J1r+LFWQXkZrfl9+ceyuDue39dLzPj3n9/zsNTlzN+eA9+feagvQqN7WUV3PLSfF6fv5ZTB3Xhd+cMpryyilMf+BAz4/Xrj6Z9jHqXseaB4VwECktKeWHGai4e3ZuMtMh/+Ubbs5+s5GevfEantilce2w/zh/Zc7/obby3qJBbX/qUwpJSrjnmAH70rVxSk/a9bjPjD28v5i//W8pZh3fjvnMO3eM4nHBfbNjO1U/PYklhCbeMHcDVY/p+tXtrfsEWzvnbxxzZryOPXzx8n3ow+6tmc3lzSWMlLZK0VNKttcy/RFKRpLnB44qweb+TtEDSQkkPKN6PTLlGl52exg9PyG1WYQFw/shevHTtkRzYOZ27X8vn2Pve45npK9lVseeLMsZCcWk5P508n0uemEnbtCRe/sFobhk7oFHCAkJXAPjxSQdy04n9eXn2l9zwwlzKI7hAJYR2jY178EPWFYeOWV1zzAG7HQsZ3D2Tn592EO8tKuKv7y1tlHpbsqj1dyUlAg8BJwIFwExJU8wsv0bTF8zsuhrLHgmMBgYHkz4EjgHei1a9zjUnQ3u159krjuCjZRv4w1uLuf3Vz/j7+8v40Qm5nDmkW60HimNh6uIifvrSfNYXh3oVN3wrN2q9oetPyCUlKYF7//055RVVPHDekDpv62tm/PW9Zdz/1iIGdM7g4QuG0rNj7eNcLjiiFzO/2Mwf3l7M4T3bc2S/To1Sr5nx0bKNHNojs0WcxADR7WGMAJaa2XIz2wU8D5we4bIGpAEpQCqQDKyPSpXONWNHHtCJF68ZxcRLh9O+dQo3T57PSX+cypR5a6iqit3u5JLScm59aT4XPT6D1imJvHTtkdx68oCo7zq75pgD+PlpA/nPgnX84NlZlFVUfqPNtrIKrn1mNve9uYjvDO7Ky9ceWWdYQKgH85uzBtGnUxuuf34O64tL97nO0vJKfjxpHuc/+gmXPD6DHbsq9nmdzUE0A6MbsDrseUEwraazJc2XNFlSDwAz+xh4F1gbPN40s2/cjk3SVZLyJOUVFfnVP13LJIljD8xmynWjmXDhUFKSErj+H3M4+c8f8OaCdTT1ccgPlhTx7T9OZVLeaq4+pi+vX390k55ldPlRfbj7jEN4Z2EhVz41i9Lyr0NjWdE2znhoGm8vXM/tpx7En8cfRquUPYdYm9Qk/nbBULaXVfLD5+ZEdE+WuhSWhM7Ce3nOl5xxWFdmr9rM1U/XHm77m2gGRm3HHGr+l/0voLeZDQbeAZ4EkNQPOAjoTihkjpc05hsrM5tgZsPMbFhWVlajFu9ccyOJkw7uzBvXH81fzhtCeVUVVz89i3EPTuPdRYVRC45dFVUsXl/C6/PXcvOL87jwsRm0Sklk8rVHctvJB8XkgPyFR/Tit2cP4oMlRVw2cSY7dlXwTv56znhwGpu27+Lpy0ZwxdF9GzR2o39OOr85axAzvtjEfW8t2vMCtfjsy62c/uA0Pl9bwt/OP5w/jR/CvWcN5oMlG7jh+bn7FER1eW9RIa/O+bLR11ubaO5YKwDCbybQHVgT3sDMNoY9fQT4bfD3mcB0M9sGIOnfwBHA1KhV69x+IiFBfOfQrpx8SGdenbuGP72zmEufmEm/7Lb06dSGLu3S6NKuFV3apdG5XRpd2qWRk5G2xy/2nbsqWVa0jaWF21hSWBL8u42VG3dQGez+SkwQV4/py40n9o/5mVvfGx66GOVPXpzHqQ98yIoN2zmkWwZ/v2DoXl+X64wh3ZjxxSYefn85w3p1aNDYnDc+XcuPJ82jfetkJl87ioO7tgPg3OE9KC4t51evL+S2lz/lt2fv/R0cw5kZEz/6grtfy2dQ90y+c2jXBp09tjeiGRgzgVxJfYAvgfHA98MbSOpiZmuDp+OA6t1Oq4ArJf2GUE/lGOBPUazVuf1OUmIC5wztzrhDu/LirNW8tWA9qzbu4JPlGyku/eY+8w5tUuickfZVkHTOSKOkrOKrgCjYvPOrEdmJCaJ3x9b0z07nlEO6kJvTln7ZbenbqW1Eu3iaylmHdyc5MYGbJs3lrMO78eszB+1zkP3itIHML9jCjyfN5fXrj97jHRfNjAf+u5Q/vrOYw3tm8vCFw75x8corju5LcWkFD/x3CRmtkrn91H0buV5eWcWdUxbw7CerOGlgDn/83mFRDwuI8jgMSacQ+qJPBB43s3sk3QXkmdmUIBDGARXAJuBaM/s8OMPqr8AYQrux/mNmN9X3Wj4Ow7mvbS+rYF1xKeu2lrJ2aynrtu5kzdbdn2/eUU5KUgJ9O7UhNyedflltyc1pS252W3p1bFPnGUjN0c5dlY0aZKs27uDUv3xAr46tmXzNkXWG0M5dlfzkxXm8/ulazj68O78+65A6Tyc2M375r3wmfvQFN53Yn+tPyN2r2rbuKOcHz81i2tKNXHPMAdzy7QP3qcfiA/ecc3tUWl5JcmJCk/wy3R+9nb+eK5/K4/yRPbnnzEHfmL92606ufCqPBWuKue3kAVwZwTGTqirj5snzeWl2AXd8ZyCXju7ToJpWbNjO5RNnsnrzDn595iC+O2zfbyHckMBoGScHO+caLNbHIJq7EwfmcPUxfXn4/eUM792BM8JuqlV95tPOXZU8dvEwjh8Q2bGOhATx27MHsa2snF/+K5/0tGTOGdo9omU/WraBa5+ZTYLg2SuOYESfb97XJdr2nz6nc841sZtPOpARvTtw28ufsmR9CQAvzy5g/ITptEpO5OUfHBlxWFRLSkzggfOGcFS/TtwyeR7/+WzdHpd5fsYqLnpsBlnpqfzz/x0Vk7AA3yXlnHP1Wl9cyqkPfEC7VsmccFAOE6Yu54i+Hfjb+UP36YKF28squOCxT1jwZTGPXzKco3K/OcK8ssr4zRsLefTDFYzpn8WD3x/S6JeyaTbXknLOuf1dTkYaD4wfwooN25kwdTnnj+zJ05eP3Oer27ZJTWLiJSPom9WGq57OY9bKzbvN31ZWwVVP5fHohyu45MjePH7xsJhf98x7GM45F4Ep89ZQUVnFWYdHdswhUoUlpZz794/ZtH0XL1w9ioO6ZFCweQdXPJnHksJt3DnuYC6M4v3N/Swp55zbjxRs3sF3//4x5ZXGz087iLtfy6esooq/nn84R+dG9yoWvkvKOef2I93bt+bpy0dSZcaPnp9Lm9QkXvnB6KiHRUP5abXOOdcM9MtuyzOXj2TyrAJ+eHy/ZnkHQA8M55xrJgZ2zeAXXQfGuow6+S4p55xzEfHAcM45FxEPDOeccxHxwHDOORcRDwznnHMR8cBwzjkXEQ8M55xzEfHAcM45F5EWcy0pSUXAyn1YRSdgQyOVs7/xbY9f8bz98bzt8PX29zKziK5B0mICY19Jyov0AlwtjW97fG47xPf2x/O2w95tv++Scs45FxEPDOeccxHxwPjahFgXEEO+7fErnrc/nrcd9mL7/RiGc865iHgPwznnXEQ8MJxzzkUk7gND0lhJiyQtlXRrrOtpapK+kPSppLmSWvRN0SU9LqlQ0mdh0zpIelvSkuDf9rGsMZrq2P47JX0ZfP5zJZ0SyxqjRVIPSe9KWihpgaQfBdNb/Odfz7Y3+LOP62MYkhKBxcCJQAEwEzjPzPJjWlgTkvQFMMzMWvwAJkljgG3AU2Z2SDDtd8AmM7s3+MHQ3sx+Gss6o6WO7b8T2GZm98eytmiT1AXoYmazJaUDs4AzgEto4Z9/Pdt+Lg387OO9hzECWGpmy81sF/A8cHqMa3JRYmZTgU01Jp8OPBn8/SSh/5FapDq2Py6Y2Vozmx38XQIsBLoRB59/PdveYPEeGN2A1WHPC9jLN3I/ZsBbkmZJuirWxcRAjpmthdD/WEB2jOuJheskzQ92WbW4XTI1SeoNDAE+Ic4+/xrbDg387OM9MFTLtHjbRzfazA4HTgb+X7DbwsWPvwEHAIcBa4Hfx7ac6JLUFngJuMHMimNdT1OqZdsb/NnHe2AUAD3CnncH1sSolpgwszXBv4XAK4R208WT9cE+3up9vYUxrqdJmdl6M6s0syrgEVrw5y8pmdAX5rNm9nIwOS4+/9q2fW8++3gPjJlArqQ+klKA8cCUGNfUZCS1CQ6CIakNcBLwWf1LtThTgIuDvy8G/hnDWppc9Zdl4Exa6OcvScBjwEIz+0PYrBb/+de17Xvz2cf1WVIAwalkfwISgcfN7J4Yl9RkJPUl1KsASAKea8nbL+kfwLGELuu8HrgDeBWYBPQEVgHfNbMWeWC4ju0/ltAuCQO+AK6u3qffkkg6CvgA+BSoCib/H6F9+S36869n28+jgZ993AeGc865yMT7LinnnHMR8sBwzjkXEQ8M55xzEfHAcM45FxEPDOeccxHxwHBNStJHwb+9JX2/kdf9f7W9VrRIOkPSL6K07m1RWu+xkl7bx3VMlHROPfOvk3TpvryGa548MFyTMrMjgz97Aw0KjODqwvXZLTDCXitabgH+uq8riWC7ok5SUiOu7nHg+kZcn2smPDBckwr75XwvcHRwHf4bJSVKuk/SzOBiaFcH7Y8NruX/HKGBR0h6NbhY4oLqCyZKuhdoFazv2fDXUsh9kj5T6N4f3wtb93uSJkv6XNKzwahYJN0rKT+o5RuXf5bUHyirvix88Kv775I+kLRY0mnB9Ii3q5bXuEfSPEnTJeWEvc45YW22ha2vrm0ZG0z7EDgrbNk7JU2Q9BbwVD21StKDwfvxOmEX6KvtfTKzHcAXklrsZUbiVWP+qnCuIW4FfmJm1V+sVwFbzWy4pFRgWvBFBqFr3BxiZiuC55eZ2SZJrYCZkl4ys1slXWdmh9XyWmcRGtF6KKFRzjMlTQ3mDQEOJnQNsWnAaEn5hC6VMMDMTFJmLescDcyuMa03cAyhC7q9K6kfcFEDtitcG2C6mf1MoXt2XAn8qpZ24WrbljxC1wk6HlgKvFBjmaHAUWa2s57PYAhwIDAIyAHygccldajnfcoDjgZm7KFmtx/xHoZrLk4CLpI0l9DlGjoCucG8GTW+VK+XNA+YTujikbnU7yjgH8GF1tYD7wPDw9ZdEFyAbS6hL/1ioBR4VNJZwI5a1tkFKKoxbZKZVZnZEmA5MKCB2xVuF1B9rGFWUNee1LYtA4AVZrbEQpd1eKbGMlPMbGfwd121juHr928N8L+gfX3vUyHQNYKa3X7EexiuuRDwQzN7c7eJ0rHA9hrPvwWMMrMdkt4D0iJYd13Kwv6uBJLMrCLYnXICoQtSXkfoF3q4nUC7GtNqXmfHiHC7alFuX1+3p5Kv/1+tIPihF+xySqlvW+qoK1x4DXXVekpt69jD+5RG6D1yLYj3MFyslADpYc/fBK5V6DLMSOqv0BV0a2oHbA7CYgBwRNi88urla5gKfC/YR59F6BdznbtKFLpvQDszewO4gdDurJoWAv1qTPuupARJBwB9gUUN2K5IfUFoNxKE7hZX2/aG+xzoE9QEoQvO1aWuWqcC44P3rwtwXDC/vvepPy30yrfxzHsYLlbmAxXBrqWJwJ8J7UKZHfxyLqL222X+B7hG0nxCX8jTw+ZNAOZLmm1m54dNfwUYBcwj9Ev5FjNbFwRObdKBf0pKI/Sr+8Za2kwFfi9JYT2BRYR2d+UA15hZqaRHI9yuSD0S1DYD+C/191IIargKeF3SBuBD4JA6mtdV6yuEeg6fAouDbYT636fRwC8bvHWuWfOr1Tq3lyT9GfiXmb0jaSLwmplNjnFZMSdpCHCTmV0Y61pc4/JdUs7tvV8DrWNdRDPUCfh5rItwjc97GM455yLiPQznnHMR8cBwzjkXEQ8M55xzEfHAcM45FxEPDOeccxH5/0LtwW5gfLgtAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "parameters = L_layer_model(X_train, y_train, layers_dims, num_iterations = 2500, print_cost = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7303370786516854\n"
     ]
    }
   ],
   "source": [
    "predictions_train = predict(X_train, y_train, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7052238805970149\n"
     ]
    }
   ],
   "source": [
    "predictions_test = predict(X_test, y_test, parameters)"
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "neural-networks-deep-learning",
   "graded_item_id": "c4HO0",
   "launcher_item_id": "lSYZM"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
